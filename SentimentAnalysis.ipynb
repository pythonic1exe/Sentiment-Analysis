{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMspNpHqF7krBxbZYYZMe0Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pythonic1exe/Sentiment-Analysis/blob/main/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuqLsolnOlcU",
        "outputId": "c3c618df-fe24-46ee-e2d0-f74c9da9f026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas matplotlib scikit-learn tensorflow nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub, shutil, os\n",
        "\n",
        "# 1. Download dataset\n",
        "path = kagglehub.dataset_download(\"arkhoshghalb/twitter-sentiment-analysis-hatred-speech\")\n",
        "print(\"Downloaded to:\", path)\n",
        "\n",
        "# 2. Define destination (Colab's sample_data folder)\n",
        "dest = \"/content/sample_data\"\n",
        "\n",
        "# 3. Copy everything from kagglehub folder to sample_data\n",
        "for file in os.listdir(path):\n",
        "    src_file = os.path.join(path, file)\n",
        "    dest_file = os.path.join(dest, file)\n",
        "    shutil.copy(src_file, dest_file)\n",
        "\n",
        "print(\"Files copied to:\", dest)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwbkZV_eZrpF",
        "outputId": "cef00e81-ffb6-4261-acc2-61becf56cfdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded to: /root/.cache/kagglehub/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech/versions/1\n",
            "Files copied to: /content/sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('sample_data/train.csv')\n",
        "\n",
        "label_col = train_df.columns[1]  # 3rd column (0-indexed)\n",
        "\n",
        "print(\"Original dataset shape:\", train_df.shape)\n",
        "print(f\"Label column: '{label_col}'\")\n",
        "print(\"Class distribution:\")\n",
        "print(train_df[label_col].value_counts())\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Get unique class values\n",
        "unique_classes = train_df[label_col].unique()\n",
        "print(f\"\\nUnique classes: {unique_classes}\")\n",
        "\n",
        "# Sample 2000 from each class\n",
        "class_samples = []\n",
        "for class_val in unique_classes:\n",
        "    class_data = train_df[train_df[label_col] == class_val]\n",
        "    print(f\"Class '{class_val}' has {len(class_data)} samples\")\n",
        "\n",
        "    if len(class_data) >= 2000:\n",
        "        sampled = class_data.sample(n=2000, random_state=42)\n",
        "        class_samples.append(sampled)\n",
        "        print(f\"Sampled 2000 from class '{class_val}'\")\n",
        "    else:\n",
        "        print(f\"Warning: Class '{class_val}' has only {len(class_data)} samples, taking all of them\")\n",
        "        class_samples.append(class_data)\n",
        "\n",
        "# Combine the samples\n",
        "balanced_df = pd.concat(class_samples, ignore_index=True)\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nBalanced dataset shape: {balanced_df.shape}\")\n",
        "print(\"Balanced class distribution:\")\n",
        "print(balanced_df[label_col].value_counts())\n",
        "\n",
        "# Now use balanced_df for your NLP processing\n",
        "train_df = balanced_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDCQYvI2ZtvV",
        "outputId": "6b79c25a-5a34-4156-bce6-c000dda1b06d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (31962, 3)\n",
            "Label column: 'label'\n",
            "Class distribution:\n",
            "label\n",
            "0    29720\n",
            "1     2242\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique classes: [0 1]\n",
            "Class '0' has 29720 samples\n",
            "Sampled 2000 from class '0'\n",
            "Class '1' has 2242 samples\n",
            "Sampled 2000 from class '1'\n",
            "\n",
            "Balanced dataset shape: (4000, 3)\n",
            "Balanced class distribution:\n",
            "label\n",
            "0    2000\n",
            "1    2000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "v35PUv56byOO",
        "outputId": "d6ece272-4a59-436c-a411-5928c55bb56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    2000\n",
              "1    2000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIVASXCYcMNn",
        "outputId": "08c45cf5-3175-47ef-b774-9aa752d73b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-07 22:26:47--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.2’\n",
            "\n",
            "glove.6B.zip.2      100%[===================>] 822.24M  5.21MB/s    in 2m 39s  \n",
            "\n",
            "2025-09-07 22:29:26 (5.17 MB/s) - ‘glove.6B.zip.2’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFmr-DrRc-Ix",
        "outputId": "c68f9735-98df-4216-94e7-b9b1b62868db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "words=dict() # empty dictionary to store word embeddings\n",
        "\n",
        "def add_to_dict(d,filename):\n",
        "  with open(filename,'r') as file: # open the GloVe file\n",
        "    for line in file.readlines():  # read line by line\n",
        "      line = line.split(' ') # line split converts the string to a list separated by spaces\n",
        "\n",
        "      try:\n",
        "        d[line[0]] = np.array(line[1:],dtype=float) # word followed by its 50d vector representation\n",
        "      except:\n",
        "        continue"
      ],
      "metadata": {
        "id": "AfteQHAHdvY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_to_dict(words,'glove.6B.50d.txt')"
      ],
      "metadata": {
        "id": "YZ3NPJYae07X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(words) # length of glove words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtfPhPQFe_fT",
        "outputId": "a3af8455-7edd-4e95-ddd8-31d321dcae18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk # for natural language processing nlp\n",
        "\n",
        "nltk.download('wordnet') # a dictionary(literal) of english words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KKdCC5Wh19c",
        "outputId": "2df818e7-a14f-4a0a-b5f9-ba2f9741014b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.RegexpTokenizer(r'\\w+') # gives clean tokens without punctuation.\n",
        "\n",
        "tokenizer.tokenize(\"@Wassup l'il boy, watchu doin?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XuJ_MB1h4Ya",
        "outputId": "c3a336b5-139b-4b35-db12-f830293eb878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wassup', 'l', 'il', 'boy', 'watchu', 'doin']"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer() # reduces a word to its lemma which is the dictionary/base form\n",
        "lemmatizer.lemmatize('feet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fr8DhWlhjMOw",
        "outputId": "bf8674e5-f695-420c-b0eb-1a1fb6ab1474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'foot'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def message_to_token_list(s): # for tokenization and lemmatization\n",
        "  tokens=tokenizer.tokenize(s)\n",
        "  lowercased_tokens = [t.lower() for t in tokens] # for lowercasing\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(t) for t in lowercased_tokens] # lemmatize the tokens in lowercased form\n",
        "  useful_tokens = [t for t in lemmatized_tokens if t in words] # useful tokens are only those which also have glove vector embeddings\n",
        "\n",
        "  return useful_tokens\n",
        "\n",
        "message_to_token_list(\"hello brothers, how are ya'll doing?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JDIy5WXjq-1",
        "outputId": "f9850f21-951b-493f-a360-f8a4d83cbaf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'brother', 'how', 'are', 'ya', 'll', 'doing']"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def message_to_word_vectors(message,word_dict=words):\n",
        "  processed_list_of_tokens = message_to_token_list(message) # processed tokens\n",
        "\n",
        "  vectors = [] # list of vectors initialized\n",
        "\n",
        "  for token in processed_list_of_tokens: # iterate through every token processed\n",
        "    if token not in word_dict: # if it is not in glove dictionary skip it\n",
        "      continue\n",
        "\n",
        "    token_vector = word_dict[token] # 50d vector embedding of the token\n",
        "    vectors.append(token_vector) # add it to the list\n",
        "\n",
        "  return np.array(vectors,dtype=float) # return the list of vectors as a numpy array"
      ],
      "metadata": {
        "id": "gF-NUyyRlpC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_to_word_vectors(\"Me boy\").shape # 2 words with 50d vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3p9IQznnUIR",
        "outputId": "95c387d1-dfd9-4ad3-ab2e-cff101a08d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_to_word_vectors(\"Me boy\") # vector representation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNUY27rMn2x-",
        "outputId": "8dbbed9c-4c26-4f7e-a6a9-65afc967b590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.14525 ,  0.31265 ,  0.15184 , -0.63708 ,  0.63553 , -0.50295 ,\n",
              "        -0.23214 ,  0.52892 , -0.58629 ,  0.53935 , -0.3055  ,  1.0357  ,\n",
              "        -0.77989 , -0.19387 ,  1.2215  ,  0.24521 ,  0.26144 ,  0.22439 ,\n",
              "         0.15584 , -0.79146 , -0.65262 ,  1.3211  ,  0.76618 ,  0.38234 ,\n",
              "         1.4453  , -2.2643  , -1.1505  ,  0.50373 ,  1.2651  , -1.5903  ,\n",
              "         3.0518  ,  0.84118 , -0.69543 ,  0.29985 , -0.49151 , -0.22312 ,\n",
              "         0.59528 , -0.076347,  0.52358 , -0.50134 ,  0.22483 ,  0.01546 ,\n",
              "        -0.088005,  0.21282 ,  0.28545 , -0.15976 , -0.16777 , -0.50895 ,\n",
              "         0.14322 ,  1.0118  ],\n",
              "       [-0.32345 ,  0.23332 , -0.20082 , -0.52848 ,  1.0926  ,  0.62445 ,\n",
              "        -0.99859 ,  0.28085 ,  0.088326,  0.36919 ,  0.32199 ,  0.3499  ,\n",
              "         0.067459,  0.24211 ,  0.92565 , -0.32581 , -0.99134 ,  0.80767 ,\n",
              "        -0.22845 ,  0.40076 , -0.8577  ,  1.3836  ,  0.056439,  0.76561 ,\n",
              "         0.3608  , -2.0692  , -0.46679 ,  0.12359 ,  0.35127 , -0.77092 ,\n",
              "         2.2064  , -0.42605 , -0.24279 ,  0.3832  ,  0.6069  ,  0.62835 ,\n",
              "         0.31825 , -0.8851  ,  0.38329 , -1.146   , -0.41949 ,  0.2606  ,\n",
              "        -0.6568  , -0.11511 ,  1.0591  , -0.61148 ,  0.32152 , -1.3182  ,\n",
              "         0.31744 ,  0.02527 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df is the variable(df) where we loaded the dataset in the very start\n",
        "train_df = train_df.sample(frac=1,random_state=1) # shuffle data\n",
        "train_df.reset_index(drop=True, inplace=True) # re-indexing\n",
        "\n",
        "split_index_1 = int(len(train_df) * 0.7) #70%\n",
        "split_index_2 = int(len(train_df) * 0.85) #85%\n",
        "\n",
        "# training: 70%, validation: 15%, testing: 15%\n",
        "train_df, val_df, test_df = train_df[:split_index_1], train_df[split_index_1:split_index_2], train_df[split_index_2:]\n",
        "\n",
        "len(train_df), len(val_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SiU2UqToKJI",
        "outputId": "7ed792a4-445e-4057-dc1f-ae77fc750eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2800, 600, 600)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert dataset to vector form\n",
        "def df_to_X_y(dff):\n",
        "  # target y\n",
        "  y = dff['label'].to_numpy().astype(int) # convert the labels to numpy array of integers\n",
        "\n",
        "  all_word_vector_sequences = [] # list for storing vector embeddings of all the words in dataset\n",
        "\n",
        "  for message in dff['tweet']: # iterate through every message in the dataset\n",
        "    message_as_vector_seq = message_to_word_vectors(message) # convert the tweet/message to vector form\n",
        "\n",
        "    if message_as_vector_seq.shape[0]==0: # if no known tokens in glove\n",
        "      message_as_vector_seq = np.zeros(shape=(1,50)) # write a simple numpy array of 0, 50d, of 1 row\n",
        "\n",
        "    all_word_vector_sequences.append(message_as_vector_seq) # append to list\n",
        "\n",
        "  return all_word_vector_sequences, y"
      ],
      "metadata": {
        "id": "D63jR9qYp5Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = df_to_X_y(train_df)\n",
        "\n",
        "print(len(X_train), len(X_train[0])) # length of training dataset portion and length of first message\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6sA-qGUs85f",
        "outputId": "e63e3b95-4842-4af2-a8cd-c356fcc04bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2800 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = []\n",
        "\n",
        "for i in range(len(X_train)): # iterate through whole dataset\n",
        "  sequence_length.append(len(X_train[i])) # append the word length of ith message to list\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# this is to check the word lengths of each message\n",
        "plt.hist(sequence_length) # histogram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "QKgIM5tcs9VT",
        "outputId": "7efbd78b-8dd6-4719-fcd4-68606131159a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([154., 485., 539., 708., 431., 329., 125.,  24.,   3.,   2.]),\n",
              " array([ 1. ,  4.6,  8.2, 11.8, 15.4, 19. , 22.6, 26.2, 29.8, 33.4, 37. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(sequence_length).describe() # tell the facts of the whole X_train dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "IR9Rwb1wuo1K",
        "outputId": "a0917740-c1e3-4e14-93f6-44d3f8596e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2800.000000\n",
              "mean       13.021786\n",
              "std         5.626383\n",
              "min         1.000000\n",
              "25%         9.000000\n",
              "50%        13.000000\n",
              "75%        17.000000\n",
              "max        37.000000\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2800.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.021786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.626383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need every sentence to be of same length because otherwise it will be hard to\n",
        "# convert to numpy array. So, we will increase the length by adding 0 in place so that\n",
        "# required length is matched. We set the length to max 57\n",
        "\n",
        "from copy import deepcopy # for copying\n",
        "\n",
        "def pad_X(X,desired_sequnece_length=40):\n",
        "  X_copy = deepcopy(X) # deepcopy of X which is the dataset\n",
        "\n",
        "  for i, x in enumerate(X): # as every message length different use enumerate to iterate accordingly\n",
        "    x_seq_length = x.shape[0] # length of message\n",
        "    sequence_length_difference = desired_sequnece_length - x_seq_length\n",
        "\n",
        "    pad = np.zeros(shape=(sequence_length_difference,50)) # create a numpy of 0s of size sequence_length_difference\n",
        "\n",
        "    X_copy[i] = np.concatenate([x,pad]) # concatnate the message with 0 padding so required length is matched\n",
        "\n",
        "  return np.array(X_copy).astype(float) # return the padded array and convert to type float"
      ],
      "metadata": {
        "id": "thhfLrF-vu_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for 70% training dataset\n",
        "X_train = pad_X(X_train)\n",
        "\n",
        "X_train.shape # every message is now of same length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKTYz3PYwTnJ",
        "outputId": "8807790f-bf39-4a56-e0c1-85f356ca71df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2800, 40, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for 15% validation dataset\n",
        "X_val, y_val = df_to_X_y(val_df) # convert to vector\n",
        "X_val = pad_X(X_val) # zero padding\n",
        "\n",
        "X_val.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d7KV1S2yKxs",
        "outputId": "4fd86735-7051-4256-e388-0a18bddf50bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((600, 40, 50), (600,))"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for 15% testing dataset\n",
        "X_test, y_test = df_to_X_y(test_df) # convert to vector\n",
        "X_test = pad_X(X_test) # zero padding\n",
        "\n",
        "X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_lDXfu7y7Wm",
        "outputId": "39cfdf9b-c601-4fa7-907e-422143130c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((600, 40, 50), (600,))"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary() # summary of our architecture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "0OhMZIWC1BFM",
        "outputId": "d3dd76fd-38c4-4b52-d114-064d81a627a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_30 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m29,440\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_31 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_32 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,561\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,440</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,561</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m294,149\u001b[0m (1.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">294,149</span> (1.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,049\u001b[0m (383.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,049</span> (383.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m196,100\u001b[0m (766.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">196,100</span> (766.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential([]) # a Sequential model which is a stack of layers applied one after the other.\n",
        "\n",
        "model.add(layers.Input(shape=(40, 50))) # each input is of words 40 and 50d\n",
        "model.add(layers.LSTM(64, return_sequences=True)) # 1st lstm layer with 64 hidden units\n",
        "model.add(layers.Dropout(0.2)) # randmoly drop 20% neurons for regularization\n",
        "model.add(layers.LSTM(64, return_sequences=True)) # 2nd layer\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.LSTM(64, return_sequences=True)) # 3rd layer\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Flatten()) # takes output of sequnce and flattens it to single vector, helps in dense layer\n",
        "model.add(layers.Dense(1, activation='sigmoid')) # dense layer outputs 1 or 0 through sigmoid function"
      ],
      "metadata": {
        "id": "d6BouJESzCUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how model will learn\n",
        "from keras.losses import BinaryCrossentropy # loss function\n",
        "from keras.optimizers import Adam # optimizer for how weights are updated\n",
        "from keras.metrics import AUC # a metric for imbalanced data\n",
        "from keras.callbacks import ModelCheckpoint # callback to save model\n",
        "\n",
        "cp = ModelCheckpoint('model/best_model.keras',save_best_only= True) # for saving model, only will be saved once validation improves\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate=0.0001), # model with Adam optimizer\n",
        "              loss = BinaryCrossentropy(), # loss functiom\n",
        "              metrics = ['accuracy', AUC(name='AUC')]) # metrics of model\n"
      ],
      "metadata": {
        "id": "7DFEFaECAHHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequencies = pd.value_counts(train_df['label'])\n",
        "\n",
        "frequencies # how many example of each label in X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "CGh0OrJmAnbT",
        "outputId": "c8df9142-3d30-4702-c181-ee9a977615b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2014568285.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
            "  frequencies = pd.value_counts(train_df['label'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    1411\n",
              "0    1389\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1389</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as our dataset is imbalanced, we set the weights accordingly, giving higher weights to rare class\n",
        "weights = {\n",
        "    0: frequencies.sum() / frequencies[0], # weight of non hatred\n",
        "    1: frequencies.sum() / frequencies[1] # weight of hatred\n",
        "}\n",
        "\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PB_GskuDL6r",
        "outputId": "eed6998d-c3fe-403b-f57e-1f1ea7913427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: np.float64(2.015838732901368), 1: np.float64(1.984408221119773)}"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[cp], class_weight=weights) # train model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rkTN5EyD5AE",
        "outputId": "1c470705-fa8b-44d7-962c-c3d6fdf0d853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - AUC: 0.6427 - accuracy: 0.6039 - loss: 1.3690 - val_AUC: 0.8014 - val_accuracy: 0.7167 - val_loss: 0.6113\n",
            "Epoch 2/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - AUC: 0.8278 - accuracy: 0.7627 - loss: 1.0800 - val_AUC: 0.8447 - val_accuracy: 0.7433 - val_loss: 0.5112\n",
            "Epoch 3/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - AUC: 0.8708 - accuracy: 0.7938 - loss: 0.9147 - val_AUC: 0.8636 - val_accuracy: 0.7950 - val_loss: 0.4665\n",
            "Epoch 4/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - AUC: 0.8897 - accuracy: 0.8132 - loss: 0.8412 - val_AUC: 0.8708 - val_accuracy: 0.8033 - val_loss: 0.4516\n",
            "Epoch 5/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - AUC: 0.8919 - accuracy: 0.8258 - loss: 0.8289 - val_AUC: 0.8761 - val_accuracy: 0.8083 - val_loss: 0.4451\n",
            "Epoch 6/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - AUC: 0.8916 - accuracy: 0.8308 - loss: 0.8253 - val_AUC: 0.8748 - val_accuracy: 0.8000 - val_loss: 0.4661\n",
            "Epoch 7/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - AUC: 0.9067 - accuracy: 0.8259 - loss: 0.7739 - val_AUC: 0.8801 - val_accuracy: 0.8167 - val_loss: 0.4389\n",
            "Epoch 8/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - AUC: 0.9053 - accuracy: 0.8425 - loss: 0.7752 - val_AUC: 0.8805 - val_accuracy: 0.8233 - val_loss: 0.4452\n",
            "Epoch 9/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - AUC: 0.9060 - accuracy: 0.8383 - loss: 0.7781 - val_AUC: 0.8815 - val_accuracy: 0.8267 - val_loss: 0.4360\n",
            "Epoch 10/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - AUC: 0.9151 - accuracy: 0.8418 - loss: 0.7385 - val_AUC: 0.8834 - val_accuracy: 0.8100 - val_loss: 0.4360\n",
            "Epoch 11/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - AUC: 0.9174 - accuracy: 0.8438 - loss: 0.7328 - val_AUC: 0.8851 - val_accuracy: 0.8300 - val_loss: 0.4340\n",
            "Epoch 12/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - AUC: 0.9218 - accuracy: 0.8472 - loss: 0.7157 - val_AUC: 0.8867 - val_accuracy: 0.8200 - val_loss: 0.4391\n",
            "Epoch 13/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - AUC: 0.9120 - accuracy: 0.8350 - loss: 0.7523 - val_AUC: 0.8849 - val_accuracy: 0.8333 - val_loss: 0.4435\n",
            "Epoch 14/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - AUC: 0.9294 - accuracy: 0.8635 - loss: 0.6795 - val_AUC: 0.8881 - val_accuracy: 0.8250 - val_loss: 0.4399\n",
            "Epoch 15/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - AUC: 0.9242 - accuracy: 0.8518 - loss: 0.7070 - val_AUC: 0.8876 - val_accuracy: 0.8250 - val_loss: 0.4286\n",
            "Epoch 16/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - AUC: 0.9302 - accuracy: 0.8573 - loss: 0.6730 - val_AUC: 0.8875 - val_accuracy: 0.8283 - val_loss: 0.4370\n",
            "Epoch 17/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - AUC: 0.9270 - accuracy: 0.8614 - loss: 0.6878 - val_AUC: 0.8877 - val_accuracy: 0.8233 - val_loss: 0.4411\n",
            "Epoch 18/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - AUC: 0.9216 - accuracy: 0.8501 - loss: 0.7138 - val_AUC: 0.8927 - val_accuracy: 0.8267 - val_loss: 0.4201\n",
            "Epoch 19/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - AUC: 0.9396 - accuracy: 0.8654 - loss: 0.6312 - val_AUC: 0.8912 - val_accuracy: 0.8300 - val_loss: 0.4355\n",
            "Epoch 20/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - AUC: 0.9387 - accuracy: 0.8645 - loss: 0.6405 - val_AUC: 0.8955 - val_accuracy: 0.8400 - val_loss: 0.4201\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e6e946a96a0>"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 epoch is one full pass of the training dataset through the model."
      ],
      "metadata": {
        "id": "1LI4m6McELOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "best_model = load_model('model/best_model.keras')"
      ],
      "metadata": {
        "id": "aep8JkQdFv8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = (best_model.predict(X_test) > 0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3doHlImGDD2",
        "outputId": "1b5d567f-86e0-40ac-9433-2cf0f453b675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test,test_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgsPuZkIGSod",
        "outputId": "78270541-4ec3-4c1e-85c1-a4135dcb8769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.85       291\n",
            "           1       0.85      0.86      0.86       309\n",
            "\n",
            "    accuracy                           0.85       600\n",
            "   macro avg       0.85      0.85      0.85       600\n",
            "weighted avg       0.85      0.85      0.85       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwBchfzubMuz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}