{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1SAynXOjnhhPZmo0apJ3c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pythonic1exe/Sentiment-Analysis/blob/main/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuqLsolnOlcU",
        "outputId": "5d6e820a-44e7-4216-803e-75cc5663564d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas matplotlib scikit-learn tensorflow nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub, shutil, os\n",
        "\n",
        "# 1. Download dataset\n",
        "path = kagglehub.dataset_download(\"arkhoshghalb/twitter-sentiment-analysis-hatred-speech\")\n",
        "print(\"Downloaded to:\", path)\n",
        "\n",
        "# 2. Define destination (Colab's sample_data folder)\n",
        "dest = \"/content/sample_data\"\n",
        "\n",
        "# 3. Copy everything from kagglehub folder to sample_data\n",
        "for file in os.listdir(path):\n",
        "    src_file = os.path.join(path, file)\n",
        "    dest_file = os.path.join(dest, file)\n",
        "    shutil.copy(src_file, dest_file)\n",
        "\n",
        "print(\"Files copied to:\", dest)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwbkZV_eZrpF",
        "outputId": "9bbbea94-39dd-4ce8-b3f1-375d42760f2b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/arkhoshghalb/twitter-sentiment-analysis-hatred-speech?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.89M/1.89M [00:00<00:00, 90.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Downloaded to: /root/.cache/kagglehub/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech/versions/1\n",
            "Files copied to: /content/sample_data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_df = pd.read_csv('sample_data/train.csv')\n",
        "\n",
        "label_col = train_df.columns[1]  # 3rd column (0-indexed)\n",
        "\n",
        "print(\"Original dataset shape:\", train_df.shape)\n",
        "print(f\"Label column: '{label_col}'\")\n",
        "print(\"Class distribution:\")\n",
        "print(train_df[label_col].value_counts())\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Get unique class values\n",
        "unique_classes = train_df[label_col].unique()\n",
        "print(f\"\\nUnique classes: {unique_classes}\")\n",
        "\n",
        "# Sample 2000 from each class\n",
        "class_samples = []\n",
        "for class_val in unique_classes:\n",
        "    class_data = train_df[train_df[label_col] == class_val]\n",
        "    print(f\"Class '{class_val}' has {len(class_data)} samples\")\n",
        "\n",
        "    if len(class_data) >= 2000:\n",
        "        sampled = class_data.sample(n=2000, random_state=42)\n",
        "        class_samples.append(sampled)\n",
        "        print(f\"Sampled 2000 from class '{class_val}'\")\n",
        "    else:\n",
        "        print(f\"Warning: Class '{class_val}' has only {len(class_data)} samples, taking all of them\")\n",
        "        class_samples.append(class_data)\n",
        "\n",
        "# Combine the samples\n",
        "balanced_df = pd.concat(class_samples, ignore_index=True)\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nBalanced dataset shape: {balanced_df.shape}\")\n",
        "print(\"Balanced class distribution:\")\n",
        "print(balanced_df[label_col].value_counts())\n",
        "\n",
        "# Now use balanced_df for your NLP processing\n",
        "train_df = balanced_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDCQYvI2ZtvV",
        "outputId": "6e3bc530-a81d-4b48-bb23-e4ecb4f8f59f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (31962, 3)\n",
            "Label column: 'label'\n",
            "Class distribution:\n",
            "label\n",
            "0    29720\n",
            "1     2242\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique classes: [0 1]\n",
            "Class '0' has 29720 samples\n",
            "Sampled 2000 from class '0'\n",
            "Class '1' has 2242 samples\n",
            "Sampled 2000 from class '1'\n",
            "\n",
            "Balanced dataset shape: (4000, 3)\n",
            "Balanced class distribution:\n",
            "label\n",
            "0    2000\n",
            "1    2000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "v35PUv56byOO",
        "outputId": "624b4ae3-af13-4b1c-956b-a4798b7fe5ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    2000\n",
              "1    2000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIVASXCYcMNn",
        "outputId": "6352573f-c71c-4168-df1a-f01f9cb88217"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-08 17:56:31--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.2’\n",
            "\n",
            "glove.6B.zip.2      100%[===================>] 822.24M  4.95MB/s    in 2m 39s  \n",
            "\n",
            "2025-09-08 17:59:10 (5.16 MB/s) - ‘glove.6B.zip.2’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove.6B.zip.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFmr-DrRc-Ix",
        "outputId": "ba61de6f-715c-4733-e4af-21aa3c0ad830"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip.2\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "words=dict() # empty dictionary to store word embeddings\n",
        "\n",
        "def add_to_dict(d,filename):\n",
        "  with open(filename,'r') as file: # open the GloVe file\n",
        "    for line in file.readlines():  # read line by line\n",
        "      line = line.split(' ') # line split converts the string to a list separated by spaces\n",
        "\n",
        "      try:\n",
        "        d[line[0]] = np.array(line[1:],dtype=float) # word followed by its 50d vector representation\n",
        "      except:\n",
        "        continue"
      ],
      "metadata": {
        "id": "AfteQHAHdvY0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_to_dict(words,'glove.6B.50d.txt')"
      ],
      "metadata": {
        "id": "YZ3NPJYae07X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(words) # length of glove words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtfPhPQFe_fT",
        "outputId": "eef90228-d443-49cf-cf68-d3561cf5eeed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk # for natural language processing nlp\n",
        "\n",
        "nltk.download('wordnet') # a dictionary(literal) of english words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KKdCC5Wh19c",
        "outputId": "b40740cc-acf8-43b2-f270-a26014b7f021"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.RegexpTokenizer(r'\\w+') # gives clean tokens without punctuation.\n",
        "\n",
        "tokenizer.tokenize(\"@Wassup l'il boy, watchu doin?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XuJ_MB1h4Ya",
        "outputId": "168c83a2-3852-47bb-c155-e3453c016591"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wassup', 'l', 'il', 'boy', 'watchu', 'doin']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer() # reduces a word to its lemma which is the dictionary/base form\n",
        "lemmatizer.lemmatize('feet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fr8DhWlhjMOw",
        "outputId": "4c9b3730-6d0b-4ad8-cdd7-0bf0bd24cb77"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'foot'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def message_to_token_list(s): # for tokenization and lemmatization\n",
        "  tokens=tokenizer.tokenize(s)\n",
        "  lowercased_tokens = [t.lower() for t in tokens] # for lowercasing\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(t) for t in lowercased_tokens] # lemmatize the tokens in lowercased form\n",
        "  useful_tokens = [t for t in lemmatized_tokens if t in words] # useful tokens are only those which also have glove vector embeddings\n",
        "\n",
        "  return useful_tokens\n",
        "\n",
        "message_to_token_list(\"hello brothers, how are ya'll doing?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JDIy5WXjq-1",
        "outputId": "56af5abb-a4b0-422f-ad4c-1ba35301a093"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'brother', 'how', 'are', 'ya', 'll', 'doing']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def message_to_word_vectors(message,word_dict=words):\n",
        "  processed_list_of_tokens = message_to_token_list(message) # processed tokens\n",
        "\n",
        "  vectors = [] # list of vectors initialized\n",
        "\n",
        "  for token in processed_list_of_tokens: # iterate through every token processed\n",
        "    if token not in word_dict: # if it is not in glove dictionary skip it\n",
        "      continue\n",
        "\n",
        "    token_vector = word_dict[token] # 50d vector embedding of the token\n",
        "    vectors.append(token_vector) # add it to the list\n",
        "\n",
        "  return np.array(vectors,dtype=float) # return the list of vectors as a numpy array"
      ],
      "metadata": {
        "id": "gF-NUyyRlpC9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_to_word_vectors(\"Me boy\").shape # 2 words with 50d vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3p9IQznnUIR",
        "outputId": "2701dfd6-5682-45bc-e74b-0c575c830c3a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_to_word_vectors(\"Me boy\") # vector representation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNUY27rMn2x-",
        "outputId": "4cb30e76-b67a-4f0a-cbc0-7d6d2993e0c6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.14525 ,  0.31265 ,  0.15184 , -0.63708 ,  0.63553 , -0.50295 ,\n",
              "        -0.23214 ,  0.52892 , -0.58629 ,  0.53935 , -0.3055  ,  1.0357  ,\n",
              "        -0.77989 , -0.19387 ,  1.2215  ,  0.24521 ,  0.26144 ,  0.22439 ,\n",
              "         0.15584 , -0.79146 , -0.65262 ,  1.3211  ,  0.76618 ,  0.38234 ,\n",
              "         1.4453  , -2.2643  , -1.1505  ,  0.50373 ,  1.2651  , -1.5903  ,\n",
              "         3.0518  ,  0.84118 , -0.69543 ,  0.29985 , -0.49151 , -0.22312 ,\n",
              "         0.59528 , -0.076347,  0.52358 , -0.50134 ,  0.22483 ,  0.01546 ,\n",
              "        -0.088005,  0.21282 ,  0.28545 , -0.15976 , -0.16777 , -0.50895 ,\n",
              "         0.14322 ,  1.0118  ],\n",
              "       [-0.32345 ,  0.23332 , -0.20082 , -0.52848 ,  1.0926  ,  0.62445 ,\n",
              "        -0.99859 ,  0.28085 ,  0.088326,  0.36919 ,  0.32199 ,  0.3499  ,\n",
              "         0.067459,  0.24211 ,  0.92565 , -0.32581 , -0.99134 ,  0.80767 ,\n",
              "        -0.22845 ,  0.40076 , -0.8577  ,  1.3836  ,  0.056439,  0.76561 ,\n",
              "         0.3608  , -2.0692  , -0.46679 ,  0.12359 ,  0.35127 , -0.77092 ,\n",
              "         2.2064  , -0.42605 , -0.24279 ,  0.3832  ,  0.6069  ,  0.62835 ,\n",
              "         0.31825 , -0.8851  ,  0.38329 , -1.146   , -0.41949 ,  0.2606  ,\n",
              "        -0.6568  , -0.11511 ,  1.0591  , -0.61148 ,  0.32152 , -1.3182  ,\n",
              "         0.31744 ,  0.02527 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df is the variable(df) where we loaded the dataset in the very start\n",
        "train_df = train_df.sample(frac=1,random_state=1) # shuffle data\n",
        "train_df.reset_index(drop=True, inplace=True) # re-indexing\n",
        "\n",
        "split_index_1 = int(len(train_df) * 0.7) #70%\n",
        "split_index_2 = int(len(train_df) * 0.85) #85%\n",
        "\n",
        "# training: 70%, validation: 15%, testing: 15%\n",
        "train_df, val_df, test_df = train_df[:split_index_1], train_df[split_index_1:split_index_2], train_df[split_index_2:]\n",
        "\n",
        "len(train_df), len(val_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SiU2UqToKJI",
        "outputId": "0e3b1ef0-a1cb-4183-ca2a-efe0bf93bd59"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2800, 600, 600)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert dataset to vector form\n",
        "def df_to_X_y(dff):\n",
        "  # target y\n",
        "  y = dff['label'].to_numpy().astype(int) # convert the labels to numpy array of integers\n",
        "\n",
        "  all_word_vector_sequences = [] # list for storing vector embeddings of all the words in dataset\n",
        "\n",
        "  for message in dff['tweet']: # iterate through every message in the dataset\n",
        "    message_as_vector_seq = message_to_word_vectors(message) # convert the tweet/message to vector form\n",
        "\n",
        "    if message_as_vector_seq.shape[0]==0: # if no known tokens in glove\n",
        "      message_as_vector_seq = np.zeros(shape=(1,50)) # write a simple numpy array of 0, 50d, of 1 row\n",
        "\n",
        "    all_word_vector_sequences.append(message_as_vector_seq) # append to list\n",
        "\n",
        "  return all_word_vector_sequences, y"
      ],
      "metadata": {
        "id": "D63jR9qYp5Um"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = df_to_X_y(train_df)\n",
        "\n",
        "print(len(X_train), len(X_train[0])) # length of training dataset portion and length of first message\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6sA-qGUs85f",
        "outputId": "95b61a8e-441b-47d5-ce6a-6f33231a88ae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2800 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = []\n",
        "\n",
        "for i in range(len(X_train)): # iterate through whole dataset\n",
        "  sequence_length.append(len(X_train[i])) # append the word length of ith message to list\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# this is to check the word lengths of each message\n",
        "plt.hist(sequence_length) # histogram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "QKgIM5tcs9VT",
        "outputId": "c7922615-76c1-45bf-a6e8-6d828cdabe4f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([154., 485., 539., 708., 431., 329., 125.,  24.,   3.,   2.]),\n",
              " array([ 1. ,  4.6,  8.2, 11.8, 15.4, 19. , 22.6, 26.2, 29.8, 33.4, 37. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJvBJREFUeJzt3X9QVfed//EXCFwVvZegcq+soKRJozRqGkzgbtK0G1nRkoxZSTd2XUsaRycU3SqJVXaMJrYTHLsbUzv+2Haz6k5jbd2pyYqjCWLE3XhFJXFiNLKaNcEsXrBxuVdN+SGc7x/9crY3aszlh/fD5fmYOTNyzufC+zPHGZ5zuVxiLMuyBAAAYJDYSA8AAADweQQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOPERXqArujo6FB9fb2GDh2qmJiYSI8DAAC+BMuydOnSJaWmpio29oufI+mTgVJfX6+0tLRIjwEAALrg3LlzGjVq1Beu6ZOBMnToUEl/3KDT6YzwNAAA4MsIBoNKS0uzv49/kT4ZKJ0/1nE6nQQKAAB9zJd5eQYvkgUAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHHiwlk8ZswYffzxx9ec/8EPfqB169apublZzzzzjLZt26aWlhbl5eVp/fr1crvd9tq6ujoVFRXprbfe0pAhQ1RYWKiysjLFxYU1ChARY5buivQIYftoVX6kRwCAsIX1DMqRI0d0/vx5+6ioqJAkfec735EkLVq0SDt37tT27dtVVVWl+vp6zZgxw358e3u78vPz1draqoMHD2rLli3avHmzli9f3oNbAgAAfV2MZVlWVx+8cOFClZeX6/Tp0woGgxoxYoS2bt2qxx9/XJJ06tQpjRs3Tj6fTzk5Odq9e7ceeeQR1dfX28+qbNy4UUuWLNGFCxeUkJDwpb5uMBiUy+VSIBCQ0+ns6vhA2HgGBQC6Lpzv311+DUpra6t+9atf6amnnlJMTIxqamrU1tam3Nxce83YsWOVnp4un88nSfL5fBo/fnzIj3zy8vIUDAZ14sSJG36tlpYWBYPBkAMAAESvLgfKa6+9pqamJj355JOSJL/fr4SEBCUlJYWsc7vd8vv99po/jZPO653XbqSsrEwul8s+0tLSujo2AADoA7ocKK+88oqmTZum1NTUnpznukpLSxUIBOzj3Llzvf41AQBA5HTpV2c+/vhj7d27V7/73e/scx6PR62trWpqagp5FqWhoUEej8dec/jw4ZDP1dDQYF+7EYfDIYfD0ZVRAQBAH9SlZ1A2bdqklJQU5ef/34vvsrKyFB8fr8rKSvtcbW2t6urq5PV6JUler1fHjx9XY2OjvaaiokJOp1OZmZld3QMAAIgyYT+D0tHRoU2bNqmwsDDkvUtcLpfmzJmjkpISJScny+l0asGCBfJ6vcrJyZEkTZkyRZmZmZo9e7ZWr14tv9+vZcuWqbi4mGdIAACALexA2bt3r+rq6vTUU09dc23NmjWKjY1VQUFByBu1dRowYIDKy8tVVFQkr9erxMREFRYWauXKld3bBQAAiCrdeh+USOF9UBApvA8KAHTdLXkfFAAAgN5CoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDhhB8r//M//6G//9m81bNgwDRo0SOPHj9fRo0ft65Zlafny5Ro5cqQGDRqk3NxcnT59OuRzXLx4UbNmzZLT6VRSUpLmzJmjy5cvd383AAAgKoQVKP/7v/+rBx54QPHx8dq9e7dOnjypf/zHf9Rtt91mr1m9erXWrl2rjRs3qrq6WomJicrLy1Nzc7O9ZtasWTpx4oQqKipUXl6uAwcOaN68eT23KwAA0KfFWJZlfdnFS5cu1dtvv63/+I//uO51y7KUmpqqZ555Rs8++6wkKRAIyO12a/PmzZo5c6Y++OADZWZm6siRI5o0aZIkac+ePfr2t7+tTz75RKmpqTedIxgMyuVyKRAIyOl0ftnxgW4bs3RXpEcI20er8iM9AgBICu/7d1jPoPz7v/+7Jk2apO985ztKSUnR17/+df3yl7+0r589e1Z+v1+5ubn2OZfLpezsbPl8PkmSz+dTUlKSHSeSlJubq9jYWFVXV1/367a0tCgYDIYcAAAgeoUVKP/93/+tDRs26M4779Qbb7yhoqIi/d3f/Z22bNkiSfL7/ZIkt9sd8ji3221f8/v9SklJCbkeFxen5ORke83nlZWVyeVy2UdaWlo4YwMAgD4mrEDp6OjQvffeqxdffFFf//rXNW/ePM2dO1cbN27srfkkSaWlpQoEAvZx7ty5Xv16AAAgssIKlJEjRyozMzPk3Lhx41RXVydJ8ng8kqSGhoaQNQ0NDfY1j8ejxsbGkOtXr17VxYsX7TWf53A45HQ6Qw4AABC9wgqUBx54QLW1tSHn/uu//kujR4+WJGVkZMjj8aiystK+HgwGVV1dLa/XK0nyer1qampSTU2NvWbfvn3q6OhQdnZ2lzcCAACiR1w4ixctWqQ///M/14svvqi//uu/1uHDh/WLX/xCv/jFLyRJMTExWrhwoX7yk5/ozjvvVEZGhp577jmlpqbqsccek/THZ1ymTp1q/2iora1N8+fP18yZM7/Ub/AAAIDoF1ag3HfffdqxY4dKS0u1cuVKZWRk6OWXX9asWbPsNT/60Y905coVzZs3T01NTXrwwQe1Z88eDRw40F7z6quvav78+Zo8ebJiY2NVUFCgtWvX9tyuAABAnxbW+6CYgvdBQaTwPigA0HW99j4oAAAAtwKBAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOPERXoA9F9jlu6K9AgAAEPxDAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOOEFSjPP/+8YmJiQo6xY8fa15ubm1VcXKxhw4ZpyJAhKigoUENDQ8jnqKurU35+vgYPHqyUlBQtXrxYV69e7ZndAACAqBAX7gO+9rWvae/evf/3CeL+71MsWrRIu3bt0vbt2+VyuTR//nzNmDFDb7/9tiSpvb1d+fn58ng8OnjwoM6fP6/vfe97io+P14svvtgD2wEAANEg7ECJi4uTx+O55nwgENArr7yirVu36uGHH5Ykbdq0SePGjdOhQ4eUk5OjN998UydPntTevXvldrt1zz336Mc//rGWLFmi559/XgkJCd3fEQAA6PPCfg3K6dOnlZqaqttvv12zZs1SXV2dJKmmpkZtbW3Kzc21144dO1bp6eny+XySJJ/Pp/Hjx8vtdttr8vLyFAwGdeLEiRt+zZaWFgWDwZADAABEr7ACJTs7W5s3b9aePXu0YcMGnT17Vt/4xjd06dIl+f1+JSQkKCkpKeQxbrdbfr9fkuT3+0PipPN657UbKSsrk8vlso+0tLRwxgYAAH1MWD/imTZtmv3vCRMmKDs7W6NHj9Zvf/tbDRo0qMeH61RaWqqSkhL742AwSKQAABDFuvVrxklJSfrqV7+qM2fOyOPxqLW1VU1NTSFrGhoa7NeseDyea36rp/Pj672upZPD4ZDT6Qw5AABA9OpWoFy+fFkffvihRo4cqaysLMXHx6uystK+Xltbq7q6Onm9XkmS1+vV8ePH1djYaK+pqKiQ0+lUZmZmd0YBAABRJKwf8Tz77LN69NFHNXr0aNXX12vFihUaMGCAvvvd78rlcmnOnDkqKSlRcnKynE6nFixYIK/Xq5ycHEnSlClTlJmZqdmzZ2v16tXy+/1atmyZiouL5XA4emWDAACg7wkrUD755BN997vf1aeffqoRI0bowQcf1KFDhzRixAhJ0po1axQbG6uCggK1tLQoLy9P69evtx8/YMAAlZeXq6ioSF6vV4mJiSosLNTKlSt7dlcAAKBPi7Esy4r0EOEKBoNyuVwKBAK8HqUPG7N0V6RH6Bc+WpUf6REAQFJ437/DfqM2mIlv9gCAaMIfCwQAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHHiIj0AgN41ZumuSI8Qto9W5Ud6BAARxjMoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAME63AmXVqlWKiYnRwoUL7XPNzc0qLi7WsGHDNGTIEBUUFKihoSHkcXV1dcrPz9fgwYOVkpKixYsX6+rVq90ZBQAARJEuB8qRI0f0T//0T5owYULI+UWLFmnnzp3avn27qqqqVF9frxkzZtjX29vblZ+fr9bWVh08eFBbtmzR5s2btXz58q7vAgAARJUuBcrly5c1a9Ys/fKXv9Rtt91mnw8EAnrllVf00ksv6eGHH1ZWVpY2bdqkgwcP6tChQ5KkN998UydPntSvfvUr3XPPPZo2bZp+/OMfa926dWptbe2ZXQEAgD6tS4FSXFys/Px85ebmhpyvqalRW1tbyPmxY8cqPT1dPp9PkuTz+TR+/Hi53W57TV5enoLBoE6cOHHdr9fS0qJgMBhyAACA6BUX7gO2bdumd955R0eOHLnmmt/vV0JCgpKSkkLOu91u+f1+e82fxknn9c5r11NWVqYXXngh3FEBAEAfFdYzKOfOndMPf/hDvfrqqxo4cGBvzXSN0tJSBQIB+zh37twt+9oAAODWCytQampq1NjYqHvvvVdxcXGKi4tTVVWV1q5dq7i4OLndbrW2tqqpqSnkcQ0NDfJ4PJIkj8dzzW/1dH7cuebzHA6HnE5nyAEAAKJXWIEyefJkHT9+XMeOHbOPSZMmadasWfa/4+PjVVlZaT+mtrZWdXV18nq9kiSv16vjx4+rsbHRXlNRUSGn06nMzMwe2hYAAOjLwnoNytChQ3X33XeHnEtMTNSwYcPs83PmzFFJSYmSk5PldDq1YMECeb1e5eTkSJKmTJmizMxMzZ49W6tXr5bf79eyZctUXFwsh8PRQ9sCAAB9Wdgvkr2ZNWvWKDY2VgUFBWppaVFeXp7Wr19vXx8wYIDKy8tVVFQkr9erxMREFRYWauXKlT09CgAA6KNiLMuyIj1EuILBoFwulwKBAK9H+f/GLN0V6RGAHvPRqvxIjwCgF4Tz/Zu/xQMAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjBMX6QEA4PPGLN0V6RHC9tGq/EiPAEQVnkEBAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxgkrUDZs2KAJEybI6XTK6XTK6/Vq9+7d9vXm5mYVFxdr2LBhGjJkiAoKCtTQ0BDyOerq6pSfn6/BgwcrJSVFixcv1tWrV3tmNwAAICqEFSijRo3SqlWrVFNTo6NHj+rhhx/W9OnTdeLECUnSokWLtHPnTm3fvl1VVVWqr6/XjBkz7Me3t7crPz9fra2tOnjwoLZs2aLNmzdr+fLlPbsrAADQp8VYlmV15xMkJyfrpz/9qR5//HGNGDFCW7du1eOPPy5JOnXqlMaNGyefz6ecnBzt3r1bjzzyiOrr6+V2uyVJGzdu1JIlS3ThwgUlJCR8qa8ZDAblcrkUCATkdDq7M37U6It/uwSIJvwtHuDmwvn+3eXXoLS3t2vbtm26cuWKvF6vampq1NbWptzcXHvN2LFjlZ6eLp/PJ0ny+XwaP368HSeSlJeXp2AwaD8Lcz0tLS0KBoMhBwAAiF5hB8rx48c1ZMgQORwOPf3009qxY4cyMzPl9/uVkJCgpKSkkPVut1t+v1+S5Pf7Q+Kk83rntRspKyuTy+Wyj7S0tHDHBgAAfUjYgXLXXXfp2LFjqq6uVlFRkQoLC3Xy5MnemM1WWlqqQCBgH+fOnevVrwcAACIrLtwHJCQk6I477pAkZWVl6ciRI/rZz36mJ554Qq2trWpqagp5FqWhoUEej0eS5PF4dPjw4ZDP1/lbPp1rrsfhcMjhcIQ7KgAA6KO6/T4oHR0damlpUVZWluLj41VZWWlfq62tVV1dnbxeryTJ6/Xq+PHjamxstNdUVFTI6XQqMzOzu6MAAIAoEdYzKKWlpZo2bZrS09N16dIlbd26Vfv379cbb7whl8ulOXPmqKSkRMnJyXI6nVqwYIG8Xq9ycnIkSVOmTFFmZqZmz56t1atXy+/3a9myZSouLuYZEgAAYAsrUBobG/W9731P58+fl8vl0oQJE/TGG2/oL//yLyVJa9asUWxsrAoKCtTS0qK8vDytX7/efvyAAQNUXl6uoqIieb1eJSYmqrCwUCtXruzZXQEAgD6t2++DEgm8D8q1eB8UILJ4HxTg5m7J+6AAAAD0FgIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGCStQysrKdN9992no0KFKSUnRY489ptra2pA1zc3NKi4u1rBhwzRkyBAVFBSooaEhZE1dXZ3y8/M1ePBgpaSkaPHixbp69Wr3dwMAAKJCWIFSVVWl4uJiHTp0SBUVFWpra9OUKVN05coVe82iRYu0c+dObd++XVVVVaqvr9eMGTPs6+3t7crPz1dra6sOHjyoLVu2aPPmzVq+fHnP7QoAAPRpMZZlWV198IULF5SSkqKqqio99NBDCgQCGjFihLZu3arHH39cknTq1CmNGzdOPp9POTk52r17tx555BHV19fL7XZLkjZu3KglS5bowoULSkhIuOnXDQaDcrlcCgQCcjqdXR0/qoxZuivSIwD92ker8iM9AmC8cL5/d+s1KIFAQJKUnJwsSaqpqVFbW5tyc3PtNWPHjlV6erp8Pp8kyefzafz48XacSFJeXp6CwaBOnDhx3a/T0tKiYDAYcgAAgOjV5UDp6OjQwoUL9cADD+juu++WJPn9fiUkJCgpKSlkrdvtlt/vt9f8aZx0Xu+8dj1lZWVyuVz2kZaW1tWxAQBAH9DlQCkuLtb777+vbdu29eQ811VaWqpAIGAf586d6/WvCQAAIieuKw+aP3++ysvLdeDAAY0aNco+7/F41NraqqamppBnURoaGuTxeOw1hw8fDvl8nb/l07nm8xwOhxwOR1dGBQAAfVBYz6BYlqX58+drx44d2rdvnzIyMkKuZ2VlKT4+XpWVlfa52tpa1dXVyev1SpK8Xq+OHz+uxsZGe01FRYWcTqcyMzO7sxcAABAlwnoGpbi4WFu3btXrr7+uoUOH2q8ZcblcGjRokFwul+bMmaOSkhIlJyfL6XRqwYIF8nq9ysnJkSRNmTJFmZmZmj17tlavXi2/369ly5apuLiYZ0kAAICkMANlw4YNkqRvfetbIec3bdqkJ598UpK0Zs0axcbGqqCgQC0tLcrLy9P69evttQMGDFB5ebmKiork9XqVmJiowsJCrVy5sns7AQAAUaNb74MSKbwPyrV4HxQgsngfFODmbtn7oAAAAPQGAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHHiIj2AicYs3RXpEQAA6Nd4BgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHv2YMAD2gL/4V9I9W5Ud6BOCGeAYFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHHCDpQDBw7o0UcfVWpqqmJiYvTaa6+FXLcsS8uXL9fIkSM1aNAg5ebm6vTp0yFrLl68qFmzZsnpdCopKUlz5szR5cuXu7URAAAQPcIOlCtXrmjixIlat27dda+vXr1aa9eu1caNG1VdXa3ExETl5eWpubnZXjNr1iydOHFCFRUVKi8v14EDBzRv3ryu7wIAAESVsN9Jdtq0aZo2bdp1r1mWpZdfflnLli3T9OnTJUn/+q//Krfbrddee00zZ87UBx98oD179ujIkSOaNGmSJOnnP/+5vv3tb+sf/uEflJqa2o3tAACAaNCjr0E5e/as/H6/cnNz7XMul0vZ2dny+XySJJ/Pp6SkJDtOJCk3N1exsbGqrq7uyXEAAEAf1aN/i8fv90uS3G53yHm3221f8/v9SklJCR0iLk7Jycn2ms9raWlRS0uL/XEwGOzJsQEAgGH6xG/xlJWVyeVy2UdaWlqkRwIAAL2oRwPF4/FIkhoaGkLONzQ02Nc8Ho8aGxtDrl+9elUXL16013xeaWmpAoGAfZw7d64nxwYAAIbp0UDJyMiQx+NRZWWlfS4YDKq6ulper1eS5PV61dTUpJqaGnvNvn371NHRoezs7Ot+XofDIafTGXIAAIDoFfZrUC5fvqwzZ87YH589e1bHjh1TcnKy0tPTtXDhQv3kJz/RnXfeqYyMDD333HNKTU3VY489JkkaN26cpk6dqrlz52rjxo1qa2vT/PnzNXPmTH6DBwAASOpCoBw9elR/8Rd/YX9cUlIiSSosLNTmzZv1ox/9SFeuXNG8efPU1NSkBx98UHv27NHAgQPtx7z66quaP3++Jk+erNjYWBUUFGjt2rU9sB0AABANYizLsiI9RLiCwaBcLpcCgUCv/LhnzNJdPf45AcA0H63Kj/QI6GfC+f7dJ36LBwAA9C8ECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMExfpAQAAkTFm6a5IjxC2j1blR3oE3CI8gwIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOBENlHXr1mnMmDEaOHCgsrOzdfjw4UiOAwAADBGxQPnNb36jkpISrVixQu+8844mTpyovLw8NTY2RmokAABgiIgFyksvvaS5c+fq+9//vjIzM7Vx40YNHjxY//Iv/xKpkQAAgCEi8lb3ra2tqqmpUWlpqX0uNjZWubm58vl816xvaWlRS0uL/XEgEJAkBYPBXpmvo+WzXvm8AIDuSV+0PdIj9Bvvv5DX45+z8/u2ZVk3XRuRQPn973+v9vZ2ud3ukPNut1unTp26Zn1ZWZleeOGFa86npaX12owAAPRnrpd773NfunRJLpfrC9f0iT8WWFpaqpKSEvvjjo4OXbx4UcOGDVNMTMwNHxcMBpWWlqZz587J6XTeilGN0V/33l/3LbH3/rj3/rpvib331b1blqVLly4pNTX1pmsjEijDhw/XgAED1NDQEHK+oaFBHo/nmvUOh0MOhyPkXFJS0pf+ek6ns8/dxJ7SX/feX/ctsff+uPf+um+JvffFvd/smZNOEXmRbEJCgrKyslRZWWmf6+joUGVlpbxebyRGAgAABonYj3hKSkpUWFioSZMm6f7779fLL7+sK1eu6Pvf/36kRgIAAIaIWKA88cQTunDhgpYvXy6/36977rlHe/bsueaFs93hcDi0YsWKa3481B/01733131L7L0/7r2/7lti7/1h7zHWl/ldHwAAgFuIv8UDAACMQ6AAAADjECgAAMA4BAoAADBOVAfKunXrNGbMGA0cOFDZ2dk6fPhwpEfqVc8//7xiYmJCjrFjx0Z6rF5x4MABPfroo0pNTVVMTIxee+21kOuWZWn58uUaOXKkBg0apNzcXJ0+fToyw/awm+39ySefvOb/wdSpUyMzbA8qKyvTfffdp6FDhyolJUWPPfaYamtrQ9Y0NzeruLhYw4YN05AhQ1RQUHDNG0L2NV9m39/61reuuedPP/10hCbuORs2bNCECRPsNyTzer3avXu3fT0a73enm+09Wu/5n4raQPnNb36jkpISrVixQu+8844mTpyovLw8NTY2Rnq0XvW1r31N58+ft4///M//jPRIveLKlSuaOHGi1q1bd93rq1ev1tq1a7Vx40ZVV1crMTFReXl5am5uvsWT9ryb7V2Spk6dGvL/4Ne//vUtnLB3VFVVqbi4WIcOHVJFRYXa2to0ZcoUXblyxV6zaNEi7dy5U9u3b1dVVZXq6+s1Y8aMCE7dfV9m35I0d+7ckHu+evXqCE3cc0aNGqVVq1appqZGR48e1cMPP6zp06frxIkTkqLzfne62d6l6LznIawodf/991vFxcX2x+3t7VZqaqpVVlYWwal614oVK6yJEydGeoxbTpK1Y8cO++OOjg7L4/FYP/3pT+1zTU1NlsPhsH79619HYMLe8/m9W5ZlFRYWWtOnT4/IPLdSY2OjJcmqqqqyLOuP9zg+Pt7avn27veaDDz6wJFk+ny9SY/a4z+/bsizrm9/8pvXDH/4wckPdQrfddpv1z//8z/3mfv+pzr1bVv+451H5DEpra6tqamqUm5trn4uNjVVubq58Pl8EJ+t9p0+fVmpqqm6//XbNmjVLdXV1kR7pljt79qz8fn/I/Xe5XMrOzo76+99p//79SklJ0V133aWioiJ9+umnkR6pxwUCAUlScnKyJKmmpkZtbW0h933s2LFKT0+Pqvv++X13evXVVzV8+HDdfffdKi0t1WeffRaJ8XpNe3u7tm3bpitXrsjr9fab+y1du/dO0X7P+8RfMw7X73//e7W3t1/zrrRut1unTp2K0FS9Lzs7W5s3b9Zdd92l8+fP64UXXtA3vvENvf/++xo6dGikx7tl/H6/JF33/ndei2ZTp07VjBkzlJGRoQ8//FB///d/r2nTpsnn82nAgAGRHq9HdHR0aOHChXrggQd09913S/rjfU9ISLjmD4lG032/3r4l6W/+5m80evRopaam6r333tOSJUtUW1ur3/3udxGctmccP35cXq9Xzc3NGjJkiHbs2KHMzEwdO3Ys6u/3jfYuRfc97xSVgdJfTZs2zf73hAkTlJ2drdGjR+u3v/2t5syZE8HJcCvNnDnT/vf48eM1YcIEfeUrX9H+/fs1efLkCE7Wc4qLi/X+++9H7WusbuRG+543b5797/Hjx2vkyJGaPHmyPvzwQ33lK1+51WP2qLvuukvHjh1TIBDQv/3bv6mwsFBVVVWRHuuWuNHeMzMzo/qed4rKH/EMHz5cAwYMuObV3A0NDfJ4PBGa6tZLSkrSV7/6VZ05cybSo9xSnfe4v9//TrfffruGDx8eNf8P5s+fr/Lycr311lsaNWqUfd7j8ai1tVVNTU0h66Plvt9o39eTnZ0tSVFxzxMSEnTHHXcoKytLZWVlmjhxon72s59F/f2Wbrz364mme94pKgMlISFBWVlZqqystM91dHSosrIy5Od30e7y5cv68MMPNXLkyEiPcktlZGTI4/GE3P9gMKjq6up+df87ffLJJ/r000/7/P8Dy7I0f/587dixQ/v27VNGRkbI9aysLMXHx4fc99raWtXV1fXp+36zfV/PsWPHJKnP3/Pr6ejoUEtLS9Te7y/Suffricp7HulX6faWbdu2WQ6Hw9q8ebN18uRJa968eVZSUpLl9/sjPVqveeaZZ6z9+/dbZ8+etd5++20rNzfXGj58uNXY2Bjp0XrcpUuXrHfffdd69913LUnWSy+9ZL377rvWxx9/bFmWZa1atcpKSkqyXn/9deu9996zpk+fbmVkZFh/+MMfIjx5933R3i9dumQ9++yzls/ns86ePWvt3bvXuvfee60777zTam5ujvTo3VJUVGS5XC5r//791vnz5+3js88+s9c8/fTTVnp6urVv3z7r6NGjltfrtbxebwSn7r6b7fvMmTPWypUrraNHj1pnz561Xn/9dev222+3HnrooQhP3n1Lly61qqqqrLNnz1rvvfeetXTpUismJsZ68803LcuKzvvd6Yv2Hs33/E9FbaBYlmX9/Oc/t9LT062EhATr/vvvtw4dOhTpkXrVE088YY0cOdJKSEiw/uzP/sx64oknrDNnzkR6rF7x1ltvWZKuOQoLCy3L+uOvGj/33HOW2+22HA6HNXnyZKu2tjayQ/eQL9r7Z599Zk2ZMsUaMWKEFR8fb40ePdqaO3duVIT59fYsydq0aZO95g9/+IP1gx/8wLrtttuswYMHW3/1V39lnT9/PnJD94Cb7buurs566KGHrOTkZMvhcFh33HGHtXjxYisQCER28B7w1FNPWaNHj7YSEhKsESNGWJMnT7bjxLKi8353+qK9R/M9/1MxlmVZt+75GgAAgJuLytegAACAvo1AAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYJz/B2zrS7b3pvzjAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(sequence_length).describe() # tell the facts of the whole X_train dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "IR9Rwb1wuo1K",
        "outputId": "7ceda184-0695-4782-878f-d8ecefad6dc6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2800.000000\n",
              "mean       13.021786\n",
              "std         5.626383\n",
              "min         1.000000\n",
              "25%         9.000000\n",
              "50%        13.000000\n",
              "75%        17.000000\n",
              "max        37.000000\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2800.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.021786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.626383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need every sentence to be of same length because otherwise it will be hard to\n",
        "# convert to numpy array. So, we will increase the length by adding 0 in place so that\n",
        "# required length is matched. We set the length to max 57\n",
        "\n",
        "from copy import deepcopy # for copying\n",
        "\n",
        "def pad_X(X,desired_sequnece_length=40):\n",
        "  X_copy = deepcopy(X) # deepcopy of X which is the dataset\n",
        "\n",
        "  for i, x in enumerate(X): # as every message length different use enumerate to iterate accordingly\n",
        "    x_seq_length = x.shape[0] # length of message\n",
        "    sequence_length_difference = desired_sequnece_length - x_seq_length\n",
        "\n",
        "    pad = np.zeros(shape=(sequence_length_difference,50)) # create a numpy of 0s of size sequence_length_difference\n",
        "\n",
        "    X_copy[i] = np.concatenate([x,pad]) # concatnate the message with 0 padding so required length is matched\n",
        "\n",
        "  return np.array(X_copy).astype(float) # return the padded array and convert to type float"
      ],
      "metadata": {
        "id": "thhfLrF-vu_M"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for 70% training dataset\n",
        "X_train = pad_X(X_train)\n",
        "\n",
        "X_train.shape # every message is now of same length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKTYz3PYwTnJ",
        "outputId": "b1425641-1654-4e24-a4dd-3461ed3a6535"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2800, 40, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for 15% validation dataset\n",
        "X_val, y_val = df_to_X_y(val_df) # convert to vector\n",
        "X_val = pad_X(X_val) # zero padding\n",
        "\n",
        "X_val.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d7KV1S2yKxs",
        "outputId": "55a7667a-a7f4-40ab-8e98-2f24844c9ddf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((600, 40, 50), (600,))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for 15% testing dataset\n",
        "X_test, y_test = df_to_X_y(test_df) # convert to vector\n",
        "X_test = pad_X(X_test) # zero padding\n",
        "\n",
        "X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_lDXfu7y7Wm",
        "outputId": "18d61133-47bd-4295-d8f5-87c35e8da426"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((600, 40, 50), (600,))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential([]) # a Sequential model which is a stack of layers applied one after the other.\n",
        "\n",
        "model.add(layers.Input(shape=(40, 50))) # each input is of words 40 and 50d\n",
        "model.add(layers.LSTM(64, return_sequences=True)) # 1st lstm layer with 64 hidden units\n",
        "model.add(layers.Dropout(0.2)) # randmoly drop 20% neurons for regularization\n",
        "model.add(layers.LSTM(64, return_sequences=True)) # 2nd layer\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.LSTM(64, return_sequences=True)) # 3rd layer\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Flatten()) # takes output of sequnce and flattens it to single vector, helps in dense layer\n",
        "model.add(layers.Dense(1, activation='sigmoid')) # dense layer outputs 1 or 0 through sigmoid function"
      ],
      "metadata": {
        "id": "d6BouJESzCUW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how model will learn\n",
        "from keras.losses import BinaryCrossentropy # loss function\n",
        "from keras.optimizers import Adam # optimizer for how weights are updated\n",
        "from keras.metrics import AUC # a metric for imbalanced data\n",
        "from keras.callbacks import ModelCheckpoint # callback to save model\n",
        "\n",
        "cp = ModelCheckpoint('model/best_model.keras',save_best_only= True) # for saving model, only will be saved once validation improves\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate=0.0001), # model with Adam optimizer\n",
        "              loss = BinaryCrossentropy(), # loss functiom\n",
        "              metrics = ['accuracy', AUC(name='AUC')]) # metrics of model\n"
      ],
      "metadata": {
        "id": "7DFEFaECAHHL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequencies = pd.value_counts(train_df['label'])\n",
        "\n",
        "frequencies # how many example of each label in X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "CGh0OrJmAnbT",
        "outputId": "52ad1f71-6ff6-4f5d-c030-0095939f1a15"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2014568285.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
            "  frequencies = pd.value_counts(train_df['label'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    1411\n",
              "0    1389\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1389</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as our dataset is imbalanced, we set the weights accordingly, giving higher weights to rare class\n",
        "weights = {\n",
        "    0: frequencies.sum() / frequencies[0], # weight of non hatred\n",
        "    1: frequencies.sum() / frequencies[1] # weight of hatred\n",
        "}\n",
        "\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PB_GskuDL6r",
        "outputId": "f8765ffb-9666-4789-cf3b-abd5d006b59a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: np.float64(2.015838732901368), 1: np.float64(1.984408221119773)}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[cp], class_weight=weights) # train model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rkTN5EyD5AE",
        "outputId": "a990a84b-231c-4a49-cc27-5b701f89cb24"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - AUC: 0.5902 - accuracy: 0.5677 - loss: 1.3770 - val_AUC: 0.7738 - val_accuracy: 0.6917 - val_loss: 0.6475\n",
            "Epoch 2/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - AUC: 0.8163 - accuracy: 0.7507 - loss: 1.1420 - val_AUC: 0.8488 - val_accuracy: 0.7600 - val_loss: 0.4872\n",
            "Epoch 3/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - AUC: 0.8858 - accuracy: 0.8098 - loss: 0.8576 - val_AUC: 0.8697 - val_accuracy: 0.7750 - val_loss: 0.4542\n",
            "Epoch 4/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - AUC: 0.8862 - accuracy: 0.8075 - loss: 0.8498 - val_AUC: 0.8721 - val_accuracy: 0.7883 - val_loss: 0.4540\n",
            "Epoch 5/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - AUC: 0.9075 - accuracy: 0.8280 - loss: 0.7732 - val_AUC: 0.8798 - val_accuracy: 0.7767 - val_loss: 0.4637\n",
            "Epoch 6/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 79ms/step - AUC: 0.9043 - accuracy: 0.8208 - loss: 0.7914 - val_AUC: 0.8816 - val_accuracy: 0.8000 - val_loss: 0.4364\n",
            "Epoch 7/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - AUC: 0.9200 - accuracy: 0.8511 - loss: 0.7154 - val_AUC: 0.8839 - val_accuracy: 0.8017 - val_loss: 0.4305\n",
            "Epoch 8/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - AUC: 0.9045 - accuracy: 0.8321 - loss: 0.7837 - val_AUC: 0.8848 - val_accuracy: 0.7933 - val_loss: 0.4496\n",
            "Epoch 9/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 82ms/step - AUC: 0.9169 - accuracy: 0.8431 - loss: 0.7361 - val_AUC: 0.8880 - val_accuracy: 0.8133 - val_loss: 0.4340\n",
            "Epoch 10/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - AUC: 0.9182 - accuracy: 0.8502 - loss: 0.7273 - val_AUC: 0.8868 - val_accuracy: 0.8100 - val_loss: 0.4297\n",
            "Epoch 11/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 71ms/step - AUC: 0.9162 - accuracy: 0.8338 - loss: 0.7386 - val_AUC: 0.8880 - val_accuracy: 0.8200 - val_loss: 0.4296\n",
            "Epoch 12/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 82ms/step - AUC: 0.9271 - accuracy: 0.8530 - loss: 0.6885 - val_AUC: 0.8864 - val_accuracy: 0.8217 - val_loss: 0.4396\n",
            "Epoch 13/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - AUC: 0.9297 - accuracy: 0.8452 - loss: 0.6814 - val_AUC: 0.8913 - val_accuracy: 0.8200 - val_loss: 0.4243\n",
            "Epoch 14/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - AUC: 0.9252 - accuracy: 0.8543 - loss: 0.6950 - val_AUC: 0.8916 - val_accuracy: 0.8117 - val_loss: 0.4221\n",
            "Epoch 15/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 79ms/step - AUC: 0.9237 - accuracy: 0.8493 - loss: 0.7010 - val_AUC: 0.8916 - val_accuracy: 0.8167 - val_loss: 0.4303\n",
            "Epoch 16/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - AUC: 0.9275 - accuracy: 0.8582 - loss: 0.6913 - val_AUC: 0.8922 - val_accuracy: 0.8233 - val_loss: 0.4202\n",
            "Epoch 17/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - AUC: 0.9342 - accuracy: 0.8648 - loss: 0.6569 - val_AUC: 0.8927 - val_accuracy: 0.8200 - val_loss: 0.4215\n",
            "Epoch 18/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - AUC: 0.9314 - accuracy: 0.8513 - loss: 0.6704 - val_AUC: 0.8954 - val_accuracy: 0.8200 - val_loss: 0.4201\n",
            "Epoch 19/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - AUC: 0.9369 - accuracy: 0.8715 - loss: 0.6401 - val_AUC: 0.8969 - val_accuracy: 0.8117 - val_loss: 0.4264\n",
            "Epoch 20/20\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 72ms/step - AUC: 0.9398 - accuracy: 0.8665 - loss: 0.6283 - val_AUC: 0.8957 - val_accuracy: 0.8167 - val_loss: 0.4194\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x783cd1a47cb0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 epoch is one full pass of the training dataset through the model."
      ],
      "metadata": {
        "id": "1LI4m6McELOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "best_model = load_model('model/best_model.keras')"
      ],
      "metadata": {
        "id": "aep8JkQdFv8h"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = (best_model.predict(X_test) > 0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3doHlImGDD2",
        "outputId": "760b0326-aa6e-4242-81a1-55130b360e0b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test,test_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgsPuZkIGSod",
        "outputId": "2627c706-5e56-4180-f3aa-d0a1e6959c8e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       291\n",
            "           1       0.88      0.83      0.86       309\n",
            "\n",
            "    accuracy                           0.85       600\n",
            "   macro avg       0.86      0.86      0.85       600\n",
            "weighted avg       0.86      0.85      0.86       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "import os\n",
        "\n",
        "# configuration of Streamlit page\n",
        "st.set_page_config(\n",
        "    page_title=\"Hate Speech Detection\",\n",
        "    page_icon=\"🛡️\",\n",
        "    layout=\"centered\",\n",
        "    initial_sidebar_state=\"collapsed\"\n",
        ")\n",
        "\n",
        "# functions\n",
        "@st.cache_data\n",
        "# nltk data\n",
        "def download_nltk_data():\n",
        "    try:\n",
        "        import nltk\n",
        "        nltk.download('wordnet')\n",
        "    except ImportError:\n",
        "        st.warning(\"NLTK not available.\")\n",
        "\n",
        "@st.cache_resource\n",
        "# GloVe embeddings\n",
        "def load_glove_embeddings(filename):\n",
        "  words = dict()\n",
        "  with open(filename,'r') as file: # open the GloVe file\n",
        "    for line in file.readlines():  # read line by line\n",
        "      line = line.split(' ') # line split converts the string to a list separated by spaces\n",
        "\n",
        "      try:\n",
        "        words[line[0]] = np.array(line[1:],dtype=float) # word followed by its 50d vector representation\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    return words\n",
        "\n",
        "@st.cache_resource\n",
        "# LSTM trained model\n",
        "def load_hate_speech_model():\n",
        "  from keras.models import load_model\n",
        "  return load_model('model/best_model.keras')\n",
        "\n",
        "# defined functions of model in app.py :\n",
        "\n",
        "def message_to_token_list(s, words):\n",
        "    tokens = s.lower().split()\n",
        "    useful_tokens = [t for t in tokens if t in words]\n",
        "    return useful_tokens\n",
        "\n",
        "def message_to_word_vectors(message, word_dict):\n",
        "    tokens = message_to_token_list(message, word_dict)\n",
        "    vectors = []\n",
        "\n",
        "    for token in tokens:\n",
        "        if token in word_dict:\n",
        "            vectors.append(word_dict[token])\n",
        "\n",
        "    if not vectors:\n",
        "        return np.zeros((1, 50))\n",
        "    return np.array(vectors, dtype=float)\n",
        "\n",
        "def pad_X(X, desired_sequence_length=40):\n",
        "    X_copy = deepcopy(X)\n",
        "    x_seq_length = X.shape[0]\n",
        "    sequence_length_difference = desired_sequence_length - x_seq_length\n",
        "\n",
        "    if sequence_length_difference > 0:\n",
        "        pad = np.zeros(shape=(sequence_length_difference, 50))\n",
        "        X_copy = np.concatenate([X, pad])\n",
        "    elif sequence_length_difference < 0:\n",
        "        X_copy = X[:desired_sequence_length]\n",
        "\n",
        "    return X_copy.astype(float)\n",
        "\n",
        "# prediction of hate speech\n",
        "def predict_hate_speech(text, model, words):\n",
        "    try:\n",
        "        message_vectors = message_to_word_vectors(text, words)\n",
        "\n",
        "        if message_vectors.shape[0] == 0:\n",
        "            message_vectors = np.zeros(shape=(1, 50))\n",
        "\n",
        "        padded_vectors = pad_X(message_vectors, 40)\n",
        "        model_input = padded_vectors.reshape(1, 40, 50)\n",
        "        prediction = model.predict(model_input, verbose=0)[0][0]\n",
        "\n",
        "        return float(prediction)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Prediction error: {str(e)}\")\n",
        "        return 0.0\n",
        "\n",
        "def main():\n",
        "    # load nltk data\n",
        "    download_nltk_data()\n",
        "\n",
        "    try:\n",
        "        words = load_glove_embeddings('glove.6B.50d.txt') # GloVe embeddings\n",
        "        model = load_hate_speech_model() # model\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading model resources: {str(e)}\")\n",
        "        st.stop()\n",
        "\n",
        "    # custom CSS\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .main {\n",
        "        padding-top: 2rem;\n",
        "    }\n",
        "    .stTextArea textarea {\n",
        "        font-size: 16px !important;\n",
        "        min-height: 120px !important;\n",
        "    }\n",
        "    .prediction-box {\n",
        "        padding: 1rem;\n",
        "        border-radius: 10px;\n",
        "        margin: 1rem 0;\n",
        "        text-align: center;\n",
        "        font-size: 18px;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .hate-speech {\n",
        "        background-color: #ffebee;\n",
        "        border: 2px solid #f44336;\n",
        "        color: #c62828;\n",
        "    }\n",
        "    .no-hate-speech {\n",
        "        background-color: #e8f5e8;\n",
        "        border: 2px solid #4caf50;\n",
        "        color: #2e7d32;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # header\n",
        "    st.title(\"🛡️ Hate Speech Detection\")\n",
        "    st.markdown(\"**AI-powered text analysis using LSTM + GloVe embeddings**\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # model info\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "    with col1:\n",
        "        st.metric(\"Accuracy\", \"85%\", \"High\")\n",
        "    with col2:\n",
        "        st.metric(\"Model Type\", \"LSTM\", \"3 Layers\")\n",
        "    with col3:\n",
        "        st.metric(\"Embeddings\", \"GloVe\", \"50D\")\n",
        "    with col4:\n",
        "        st.metric(\"Sequence\", \"40\", \"Words\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # input section\n",
        "    st.subheader(\"📝 Enter Text to Analyze\")\n",
        "    user_input = st.text_area(\n",
        "        \"Type or paste your text here:\",\n",
        "        placeholder=\"Enter any text you'd like to analyze for hate speech...\",\n",
        "        help=\"The model will analyze your text and determine if it contains hate speech\"\n",
        "    )\n",
        "\n",
        "    # analysis section\n",
        "    col1, col2, col3 = st.columns([1, 2, 1])\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\"🔍 Analyze Text\", use_container_width=True, type=\"primary\"):\n",
        "            if user_input.strip():\n",
        "                with st.spinner(\"Analyzing text...\"):\n",
        "                    prediction_score = predict_hate_speech(user_input, model, words)\n",
        "\n",
        "                    is_hate_speech = prediction_score > 0.5\n",
        "                    confidence = prediction_score if is_hate_speech else (1 - prediction_score)\n",
        "\n",
        "                    st.markdown(\"---\")\n",
        "                    st.subheader(\"📊 Analysis Results\")\n",
        "\n",
        "                    if is_hate_speech:\n",
        "                        st.markdown(f\"\"\"\n",
        "                        <div class=\"prediction-box hate-speech\">\n",
        "                            ⚠️ HATE SPEECH DETECTED<br>\n",
        "                            <small>This text appears to contain hate speech content</small>\n",
        "                        </div>\n",
        "                        \"\"\", unsafe_allow_html=True)\n",
        "                    else:\n",
        "                        st.markdown(f\"\"\"\n",
        "                        <div class=\"prediction-box no-hate-speech\">\n",
        "                            ✅ NO HATE SPEECH DETECTED<br>\n",
        "                            <small>This text appears to be safe and non-harmful</small>\n",
        "                        </div>\n",
        "                        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                    col_conf1, col_conf2 = st.columns(2)\n",
        "\n",
        "                    with col_conf1:\n",
        "                        st.metric(\"Confidence Level\", f\"{confidence:.1%}\")\n",
        "\n",
        "                    with col_conf2:\n",
        "                        st.metric(\"Raw Score\", f\"{prediction_score:.4f}\")\n",
        "\n",
        "                    st.progress(confidence)\n",
        "\n",
        "                    with st.expander(\"🔧 Technical Details\"):\n",
        "                        tokens = message_to_token_list(user_input, words)\n",
        "                        original_words = len(user_input.split())\n",
        "                        processed_tokens = len(tokens)\n",
        "\n",
        "                        col_tech1, col_tech2 = st.columns(2)\n",
        "\n",
        "                        with col_tech1:\n",
        "                            st.write(f\"**Original words:** {original_words}\")\n",
        "                            st.write(f\"**Processed tokens:** {processed_tokens}\")\n",
        "                            st.write(f\"**Classification threshold:** 0.5\")\n",
        "\n",
        "                        with col_tech2:\n",
        "                            st.write(f\"**Model architecture:** 3-layer LSTM\")\n",
        "                            st.write(f\"**Sequence length:** 40 words (padded)\")\n",
        "                            st.write(f\"**Vector dimension:** 50D GloVe\")\n",
        "\n",
        "                        if tokens:\n",
        "                            st.write(f\"**Sample tokens:** {', '.join(tokens[:10])}\")\n",
        "                        else:\n",
        "                            st.write(\"**Note:** No tokens found in vocabulary\")\n",
        "            else:\n",
        "                st.warning(\"⚠️ Please enter some text to analyze.\")\n",
        "\n",
        "    # information section\n",
        "    st.markdown(\"---\")\n",
        "    st.subheader(\"ℹ️ About This Model\")\n",
        "\n",
        "    col_info1, col_info2 = st.columns(2)\n",
        "\n",
        "    with col_info1:\n",
        "        st.markdown(\"\"\"\n",
        "        **🧠 Model Architecture:**\n",
        "        - 3-layer LSTM network\n",
        "        - 64 hidden units per layer\n",
        "        - Dropout regularization (0.2)\n",
        "        - Sigmoid output activation\n",
        "\n",
        "        **📊 Training:**\n",
        "        - Balanced dataset (4,000 samples)\n",
        "        - 70% train, 15% validation, 15% test\n",
        "        - Class weight balancing applied\n",
        "        \"\"\")\n",
        "\n",
        "    with col_info2:\n",
        "        st.markdown(\"\"\"\n",
        "        **⚙️ Text Processing:**\n",
        "        - NLTK tokenization & lemmatization\n",
        "        - GloVe 6B.50d word embeddings\n",
        "        - 40-word sequence padding\n",
        "        - Binary classification (hate/no-hate)\n",
        "\n",
        "        **🔒 Privacy:**\n",
        "        - All processing done locally\n",
        "        - No data stored or logged\n",
        "        - Instant analysis results\n",
        "        \"\"\")\n",
        "\n",
        "    # footer\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\n",
        "        \"<div style='text-align: center; color: #666; padding: 1rem;'>\"\n",
        "        \"Built with TensorFlow, LSTM, and Streamlit | Hate Speech Detection AI\"\n",
        "        \"</div>\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "DwBchfzubMuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d5520f-a370-46c8-dee3-b1d14497c001"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_tunnel.py\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "import signal\n",
        "import sys\n",
        "\n",
        "# for running streamlit server\n",
        "def run_streamlit():\n",
        "    print(\"Starting Streamlit server...\")\n",
        "    try:\n",
        "        subprocess.run([\n",
        "            \"streamlit\", \"run\", \"app.py\",\n",
        "            \"--server.port\", \"8501\",\n",
        "            \"--server.headless\", \"true\",\n",
        "            \"--server.enableCORS\", \"false\",\n",
        "            \"--server.enableXsrfProtection\", \"false\"\n",
        "        ])\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Streamlit stopped by user\")\n",
        "\n",
        "# for checking if the port is already in use\n",
        "def check_port(port):\n",
        "    result = subprocess.run(['netstat', '-tulpn'], capture_output=True, text=True)\n",
        "    return str(port) in result.stdout\n",
        "\n",
        "def main():\n",
        "    print(\"🚀 Starting Hate Speech Detection App with Cloudflare Tunnel\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # kill any existing processes so that streamlit runs easily\n",
        "    print(\"Cleaning up existing processes...\")\n",
        "    subprocess.run(['pkill', '-f', 'streamlit'], capture_output=True)\n",
        "    subprocess.run(['pkill', '-f', 'cloudflared'], capture_output=True)\n",
        "    time.sleep(2)\n",
        "\n",
        "    # check if app.py exists\n",
        "    if not os.path.exists('app.py'):\n",
        "        print(\"❌ app.py not found! Please create your Streamlit app file first.\")\n",
        "        return\n",
        "\n",
        "    # start Streamlit in background because it doesnt run on colab locally\n",
        "    streamlit_thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "    streamlit_thread.start()\n",
        "\n",
        "    # wait few seconds for Streamlit to start\n",
        "    print(\"Waiting for Streamlit to start...\")\n",
        "    for i in range(15):\n",
        "        time.sleep(1)\n",
        "        if check_port(8501):\n",
        "            print(\"✅ Streamlit is running on port 8501\")\n",
        "            break\n",
        "        print(f\"Waiting... ({i+1}/15)\")\n",
        "    else:\n",
        "        print(\"❌ Streamlit failed to start on port 8501\")\n",
        "        return\n",
        "\n",
        "    # start Cloudflare tunnel\n",
        "    print(\"\\nStarting Cloudflare tunnel...\")\n",
        "    print(\"This will show your public URL below:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    try:\n",
        "        # run cloudflared in foreground to see the URL\n",
        "        subprocess.run([\n",
        "            \"cloudflared\", \"tunnel\",\n",
        "            \"--url\", \"http://localhost:8501\"\n",
        "        ])\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nShutting down...\")\n",
        "        subprocess.run(['pkill', '-f', 'streamlit'], capture_output=True)\n",
        "        subprocess.run(['pkill', '-f', 'cloudflared'], capture_output=True)\n",
        "        print(\"All processes stopped. Goodbye!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9Gr5J9VgVTE",
        "outputId": "043a79ab-c588-4684-ad88-3e1b5b399aea"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run_tunnel.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install cloudfare\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "!pip install streamlit\n",
        "\n",
        "# run the tunnel script\n",
        "!python run_tunnel.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOz8KC4UlT97",
        "outputId": "58a54569-ebe4-4308-be87-9805916644e2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Reading database ... 126378 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.8.1) over (2025.8.1) ...\n",
            "Setting up cloudflared (2025.8.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.49.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.3.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "🚀 Starting Hate Speech Detection App with Cloudflare Tunnel\n",
            "============================================================\n",
            "Cleaning up existing processes...\n",
            "Starting Streamlit server...\n",
            "Waiting for Streamlit to start...\n",
            "Waiting... (1/15)\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "✅ Streamlit is running on port 8501\n",
            "\n",
            "Starting Cloudflare tunnel...\n",
            "This will show your public URL below:\n",
            "----------------------------------------\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.199.122.226:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[90m2025-09-08T21:52:33Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-09-08T21:52:33Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m |  https://tables-edmonton-such-syracuse.trycloudflare.com                                   |\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.8.1 (Checksum a66353004197ee4c1fcb68549203824882bba62378ad4d00d234bdb8251f1114)\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update if installed by a package manager.\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 8ca02328-82d5-4c31-9642-71ec84154669\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23\n",
            "2025/09/08 21:52:36 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-09-08T21:52:36Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m99a519fd-6814-49fd-b752-53c760ca0d7c \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.23 \u001b[36mlocation=\u001b[0msea06 \u001b[36mprotocol=\u001b[0mquic\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "2025-09-08 21:53:20.191120: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757368400.646808   59704 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757368400.758096   59704 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757368401.588657   59704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757368401.588882   59704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757368401.588889   59704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757368401.588894   59704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-08 21:53:30.994482: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "\u001b[90m2025-09-08T21:54:28Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\n",
            "\n",
            "Shutting down...\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Exception ignored in atexit callback: <function clean_up at 0x78e0c03bf600>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/api.py\", line 2893, in clean_up\n",
            "All processes stopped. Goodbye!\n",
            "    clear_caches()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/api.py\", line 2918, in clear_caches\n",
            "    pjit._cpp_pjit_cache_explicit_attributes.clear()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/bootstrap.py\", line 43, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/server/server.py\", line 509, in stop\n",
            "    self._runtime.stop()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/runtime/runtime.py\", line 329, in stop\n",
            "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 844, in call_soon_threadsafe\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S0qBFX9ElZFO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}